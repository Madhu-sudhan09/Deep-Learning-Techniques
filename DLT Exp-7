import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Subset
import torchvision
import torchvision.transforms as transforms
import numpy as np
import matplotlib.pyplot as plt
import random
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])
train_dataset_full = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
test_dataset_full = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
def filter_cat_dog(dataset):
    idx = [i for i, (_, label) in enumerate(dataset) if label in [3, 5]]
    return Subset(dataset, idx)
train_dataset = filter_cat_dog(train_dataset_full)
test_dataset = filter_cat_dog(test_dataset_full)
for i in range(len(train_dataset)):
    img_idx = train_dataset.indices[i]
    if train_dataset_full.targets[img_idx] == 3:
        train_dataset_full.targets[img_idx] = 0
    elif train_dataset_full.targets[img_idx] == 5:
        train_dataset_full.targets[img_idx] = 1
for i in range(len(test_dataset)):
    img_idx = test_dataset.indices[i]
    if test_dataset_full.targets[img_idx] == 3:
        test_dataset_full.targets[img_idx] = 0
    elif test_dataset_full.targets[img_idx] == 5:
        test_dataset_full.targets[img_idx] = 1
n_train = int(len(train_dataset) * 0.8)
n_val = len(train_dataset) - n_train
train_subset, val_subset = torch.utils.data.random_split(train_dataset, [n_train, n_val])
batch_size = 64
train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=2)
val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=2)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)
print(f"Train size: {len(train_subset)}, Val size: {len(val_subset)}, Test size: {len(test_dataset)}")
class CatDogCNN(nn.Module):
    def __init__(self):
        super(CatDogCNN, self).__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),
            nn.Flatten()
        )
        self.classifier = nn.Sequential(
            nn.Linear(64 * 8 * 8, 128),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(128, 1),
            nn.Sigmoid()
        )
    def forward(self, x):
        x = self.features(x)
        x = self.classifier(x)
        return x
model = CatDogCNN().to(device)
print(model)
criterion = nn.BCELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)
epochs = 10
train_losses, val_losses, train_accs, val_accs = [], [], [], []
for epoch in range(epochs):
    model.train()
    running_loss, running_corrects = 0.0, 0.0
    for inputs, labels in train_loader:
        inputs, labels = inputs.to(device), labels.float().to(device).unsqueeze(1)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item() * inputs.size(0)
        preds = (outputs > 0.5).float()
        running_corrects += torch.sum(preds == labels.data)
    train_loss = running_loss / len(train_subset)
    train_acc = running_corrects.double() / len(train_subset)
    train_losses.append(train_loss)
    train_accs.append(train_acc.item())
    model.eval()
    running_loss, running_corrects = 0.0, 0.0
    with torch.no_grad():
        for inputs, labels in val_loader:
            inputs, labels = inputs.to(device), labels.float().to(device).unsqueeze(1)
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            running_loss += loss.item() * inputs.size(0)
            preds = (outputs > 0.5).float()
            running_corrects += torch.sum(preds == labels.data)
    val_loss = running_loss / len(val_subset)
    val_acc = running_corrects.double() / len(val_subset)
    val_losses.append(val_loss)
    val_accs.append(val_acc.item())
    print(f"Epoch {epoch+1}/{epochs} - Train Acc: {train_acc.item():.4f}, Val Acc: {val_acc.item():.4f}")
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(train_accs, label="Train Acc")
plt.plot(val_accs, label="Val Acc")
plt.legend(); plt.title("Accuracy")
plt.subplot(1, 2, 2)
plt.plot(train_losses, label="Train Loss")
plt.plot(val_losses, label="Val Loss")
plt.legend(); plt.title("Loss")
plt.show()
model.eval()
corrects = 0
with torch.no_grad():
    for inputs, labels in test_loader:
        inputs, labels = inputs.to(device), labels.float().to(device).unsqueeze(1)
        outputs = model(inputs)
        preds = (outputs > 0.5).float()
        corrects += torch.sum(preds == labels.data)
test_acc = corrects.double() / len(test_dataset)
print(f"Test Accuracy: {test_acc.item()*100:.2f}%")
def imshow(img):
    img = img / 2 + 0.5  
    npimg = img.cpu().numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.axis('off')
dataiter = iter(test_loader)
images, labels = next(dataiter)
idx = random.randint(0, images.size(0) - 1)
sample_img = images[idx]
sample_label = "Dog" if labels[idx] == 1 else "Cat"
with torch.no_grad():
    output = model(sample_img.unsqueeze(0).to(device))
    pred = output.item()
pred_label = "Dog" if pred > 0.5 else "Cat"
imshow(sample_img)
plt.title(f"True: {sample_label}, Pred: {pred_label}")
plt.show()
